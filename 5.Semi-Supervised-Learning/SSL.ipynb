{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마이크로소프트의 SSL github repository를 활용하여 실험을 수행하였음.  \n",
    "https://github.com/microsoft/Semi-supervised-learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Intro\n",
    "\n",
    "이번 실습은 Semi-supervised-learning 기법들을 직접 사용해 보고, 다른 방법론 사이의 비교를 수행해 보는 것을 목적으로 한다. 실습에서 활용하는 코드는 위에 첨부한 마이크로소프트의 SSL github repository로 다양한 SSL 알고리즘 들을 제공한다. 여기서 특히 Holistic methods에 집중하여 MixUp 방법론의 개선 연구의 흐름을 따라 MixMatch, ReMixMatch, FixMatch, FlexMatch, SimMatch에 대해 실험을 수행해 보고자 한다.  \n",
    "\n",
    "전체적인 실습의 구성은 위 다섯 가지의 방법론에 대한 간단한 이론적 소개 후, 순서대로 동일한 데이터에 대해 실험을 수행한다. 이론 설명은 고려대학교 산업경영공학과 강필성 교수님 [IME654]Business-Analytics 수업자료와 DSBA Lab Seminar 및 PYSR 자료를 참고하여 재 구성 한 것이다.  \n",
    "\n",
    "실험에는 방법론의 일반화 성능을 조금 더 강하게 살펴 보기 위해, 일반적으로 많이 사용되는 image domain이 아니라 NLP domain의 data를 활용하여 실험을 수행하였다.  \n",
    "\n",
    "추가로 실험의 결과 리포팅의 경우 본 방법론들이 각각 시간이 많이 소요 되기 때문에, 따로 terminal에서 tmux를 통해 실험을 수행하고 노트북 파일에는 코드와 결과만 이미지로 첨부하였다.\n",
    "\n",
    "\n",
    "https://sustaining-starflower-aff.notion.site/2022-2-0e068bff3023401fa9fa13e96c0269d7  \n",
    "(2022 고려대학교 산업경영공학과 강필성 교수님 [IME654]Business-Analytics 수업자료)  \n",
    "\n",
    "https://www.youtube.com/watch?v=nSJP7bn2D1U  \n",
    "(DSBA Lab Seminar 2020, 이정훈)\n",
    " \n",
    "https://youtu.be/NoPkSeKUER4  \n",
    "(DSBA Lab PYSR 2022, 고유경)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Backgorund\n",
    "## 1.1. 이론\n",
    "### 1.1.0 Stochastic Data Augmentation\n",
    " <p align=\"center\">   <image src=\"./images/2022-12-27-15-49-33.png\" width=\"60%\"/>   </p>\n",
    "\n",
    "### 1.1.1 MixMatch\n",
    " <p align=\"center\">   <image src=\"./images/2022-12-27-15-50-10.png\" width=\"60%\"/> <figcaption align=\"center\">DSBA Lab Seminar 2020, 이정훈  </figcaption>  </p>\n",
    " \n",
    " \n",
    "  기존의 MixUp 방법론의 경우 Unlabeled data만을 활용하여 MixUp을 수행하였기 때문에, 보다 정확한 정보를 줄 수 있는 labeled data를 MixUp에 함께 활용하기 위해 제안된 방법론이다.  \n",
    "\n",
    "Labeled data의 경우 사전에 정의한 image Augmentation 기법 중 하나를 임의로 적용하고, unlabeled data의 경우는 hyperparameter로 정의 되는 K번 만큼의 Stochastic Data Augmentation을 수행한다. 두 데이터 셋의 augmentation 결과를 우선 함께 shuffle 한 후 각각의 data 수 만큼을 MixUp한다. 여기서 다음과 같이 Max()를 거쳐 얻어진 λ’ 은 항상 0.5보다 크기 때문에, 항상 앞쪽에 유사한 결과를 얻게 된다.\n",
    " <p align=\"center\">   <image src=\"./images/2022-12-27-15-26-01.png\" width=\"20%\"/>  </p>\n",
    "\n",
    "그렇게 Augmented data가 준비되면 다음으로는 Labeled는 정답에 가깝게하는 Cross Entropy Loss와 Unlabeled는 guessed label에 가깝게하는 L2 Loss 학습을 수행하게 된다.\n",
    " <p align=\"center\">   <image src=\"./images/2022-12-27-15-28-31.png\" width=\"25%\"/>   </p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1.2 ReMixMatch\n",
    "MixMatch 방법론에서 다음의 두가지 목적을 가지고 개선된 모델이다.\n",
    "1. Unlabeled 데이터의 전체적인  예측  분포가 Labeled 데이터의 분포와  비슷하도록 하고\n",
    "2. Strong Augmentation을  적용하되  Guessed Label은  Weak Augmentation을  이용해서  구하자 \n",
    "\n",
    "각각의 목표는 다음 그림에 나타난 두가지 모듈 Distribution Alignment, Augmentation Anchoring을 통해 구현된다.\n",
    " <p align=\"center\">   <image src=\"./images/2022-12-27-15-57-41.png\" width=\"60%\"/>   </p>\n",
    "\n",
    "- Distribution Alignment\n",
    "  - Maximize Mutual Imformation\n",
    "    :위 식은 확률변수  𝑥, 𝑦가  독립이  아니라면  더 높은값을 가짐\n",
    "     <p align=\"center\">   <image src=\"./images/2022-12-27-16-00-27.png\" width=\"60%\"/>   </p>\n",
    "     식에서 앞쪽의 term: 예측결과의 분포가 Labeled data의 prior 분포와 가깝게! 현재는 균등한 분포일때의 식으로 다음의 식을 통해 현재 분포에 알맞게 조율된다.\n",
    "      <p align=\"center\">   <image src=\"./images/2022-12-27-16-03-10.png\" width=\"25%\"/>   </p>\n",
    "     뒤쪽의 term: 좋은 모델은 confidence가 커야\n",
    "-  Augmentation Anchoring  \n",
    "    : weak augmentation만 수행한 경우는 데이터의 다양성을 충분히 확보할 수 없고, strong augmentation을 수행한 경우는 데이터의 정보가 많이 훼손 되어 guessed label을 신뢰할 수 없다.   \n",
    "    이런 상황에서 strong augmentation을 수행하되, pseudo label의 경우는 같은 원 데이터로 부터 얻은 weak augmentaion 결과로 부터 얻겠다는 의미이다.\n",
    "설명한 부분이외에는 기존의 MixMatch와 동일하며 최종적으로 다음의 Loss를 통해 학습이 수행된다.\n",
    " <p align=\"center\">   <image src=\"./images/2022-12-27-16-16-32.png\" width=\"60%\"/>   </p>\n",
    "    앞의 두 term은 각각 labeled, unlabeled data에 대한 loss이다.\n",
    "     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 FixMatch\n",
    "이전 까지 소개한 방식이 너무 복잡하기 때문에 확실한 Weak Augmentation의 예측  결과는 바로  Strong Augmentation의 Pseudo-label로 사용하자는 접근으로 weak augmentation에 대해 anchoring 등 과정을 거치는 것이 아니라, 만약 weak augmentation의 예측 confidence가 어느 수준 이상으로 확실 하다면 그대로 strong augmentation의 pseudo label로 사용하겠다는 의미이다.  \n",
    "\n",
    "기본적인 과정은 MixMatch와 동일하고 차이가 나는 부분만을 수식과 함께 정리하면 다음과 같다.\n",
    "- Supervised Learning\n",
    "  - labeled data에 대해서는 weak augmentation을 수행한 후 모델을 통해 예측을 수행하고 Supervised cross-entropy 학습이 수행된다.\n",
    "\n",
    "   <p align=\"center\">   <image src=\"./images/2022-12-27-16-22-57.png\" width=\"23%\"/>   </p>\n",
    "- Unsupervised Learnin\n",
    "  - 정답이 없는 경우 confidence가 넘는 weak aug.의 예측 결과가 Pseudo-label 역할을 수행\n",
    "  Threshold를  넘으면  Pseudo-label 이용하고, Threshold를  넘지  않으면  loss를  계산하지 않는다. 결과적으로 학습  초기에는  대부분  threshold를 넘지  않아  supervised loss만  계산되어 별도의 장치 없이 자동으로 초반과 후반에 Labeled data와 unlabeled data의 반영 비율 조절 된다.\n",
    "\n",
    "\n",
    "    <p align=\"center\">   <image src=\"./images/2022-12-27-16-24-03.png\" width=\"40%\"/>   </p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 FlexMatch\n",
    "다음 그림에서 확인할 수 있듯이 분류 task 수행시에 범주마다 난이도가 달르기 때문에 각 범주의 난이도에 따라 서로 다른 threshold를 사용하는 것이다.\n",
    " <p align=\"center\">   <image src=\"./images/2022-12-27-16-25-59.png\" width=\"60%\"/>  <figcaption align=\"center\">DSBA Lab PYSR 2022, 고유경  </figcaption>   </p>\n",
    "\n",
    "위 과정은 Curriculum Pseudo Labeling을  통해  각  Class의  난이도에  따른  Confidence Threshold를  시점마다  다르게하는 것으로 구현되었으며, 전체적은 과정은 다음과 같다.\n",
    " <p align=\"center\">   <image src=\"./images/2022-12-27-16-27-50.png\" width=\"60%\"/>   </p>\n",
    "\n",
    "본 과정은 크게 두 가지로 나뉘는데 Learning Effect 측정, Learning Effect 정규화  및 Threshold 결정이 그것이다.\n",
    "\n",
    "- Learning Effect 측정\n",
    "  - 현재 Threshold 넘는 개수가 몇 개냐!?\n",
    "  <p align=\"center\">   <image src=\"./images/2022-12-27-16-29-31.png\" width=\"40%\"/>   </p>\n",
    "- Learning Effect 정규화  및 Threshold 결정\n",
    "  - 비율지표로 잘 맞출수록 1에 가까워져 해당 범주의 threshold는 τ에 수렴\n",
    "  <p align=\"center\">   <image src=\"./images/2022-12-27-16-30-05.png\" width=\"40%\"/>   </p>\n",
    "\n",
    "여기에 추가로 모든  Class의  threshold가  0에서  시작해서  점진적으로  증가하게 하는 Threshold Warm-Up과\n",
    " <p align=\"center\">   <image src=\"./images/2022-12-27-16-31-39.png\" width=\"30%\"/>   </p>\n",
    "학습 초기의 변동성을 완화하고 β의 크기 조절을 통해 속도를 조절하는 Non-Linear Mapping이 적용된다.\n",
    " <p align=\"center\">   <image src=\"./images/2022-12-27-16-32-05.png\" width=\"30%\"/>   </p>\n",
    "\n",
    "Loss는 다음과 같다.\n",
    " <p align=\"center\">   <image src=\"./images/2022-12-27-16-32-41.png\" width=\"60%\"/>   </p>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 SimMatch\n",
    "- Unlabeled Data에 대한 추가적인 학습 정보가 도입될 필요\n",
    "- 학습 과정 중 저장되는 Memory Buffer를 이용하자\n",
    "- 두 정보 간 차이를 최소화하도록 Loss 제안\n",
    "  - Unlabeled의 Prediction Distribution vs Memory Buffer를 Prediction Distribution으로 변환\n",
    "  - Unlabeled의 Prediction Distribution을 Representation으로 변환 vs Memory Buffer\n",
    "- Class Center : Encoder를 통과한 후 Classification Head를 통과한 벡터(의미적 정보를 보존한 벡터, semantic vector)\n",
    "- Labeled Embeddings : Encoder를 통과한 후 학습되는 MLP Layer를 통과한 벡터(labeled data의 정보를 저장하는 Memory Buffer의 역할)\n",
    " <p align=\"center\">   <image src=\"./images/2022-12-27-17-06-23.png\" width=\"60%\"/>   </p>\n",
    "\n",
    " <p align=\"center\">   <image src=\"./images/2022-12-27-17-06-45.png\" width=\"60%\"/>   </p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. repository 코드 활용 개요\n",
    "\n",
    "### 1.2.1 config 정의를 통해 실험에 활용할 hyperparameter 설정\n",
    "```python\n",
    "config = {\n",
    "    'algorithm': 'fixmatch',\n",
    "    'net': 'wrn_28_2',\n",
    "    'use_pretrain': False,  # todo: add pretrain\n",
    "    'pretrain_path': None,\n",
    "\n",
    "    # optimization configs\n",
    "    'epoch': 3,\n",
    "    'num_train_iter': 150,\n",
    "    'num_eval_iter': 50,\n",
    "    'optim': 'SGD',\n",
    "    'lr': 0.03,\n",
    "    'momentum': 0.9,\n",
    "    'batch_size': 64,\n",
    "    'eval_batch_size': 64,\n",
    "\n",
    "    # dataset configs\n",
    "    'dataset': 'cifar10',\n",
    "    'num_labels': 40,\n",
    "    'num_classes': 10,\n",
    "    'img_size': 32,\n",
    "    'crop_ratio': 0.875,\n",
    "    'data_dir': './data',\n",
    "\n",
    "    # algorithm specific configs\n",
    "    'hard_label': True,\n",
    "    'uratio': 3,\n",
    "    'ulb_loss_ratio': 1.0,\n",
    "\n",
    "    # device configs\n",
    "    'gpu': 0,\n",
    "    'world_size': 1,\n",
    "    'distributed': False,\n",
    "}\n",
    "config = get_config(config)\n",
    "```\n",
    "\n",
    "### 1.2.2 모델을 선언하고 알고리즘의 특정\n",
    "```python\n",
    "from semilearn import get_dataset, get_data_loader, get_net_builder, get_algorithm, get_config, Trainer\n",
    "\n",
    "algorithm = get_algorithm(config,  get_net_builder(config.net, from_name=False), tb_log=None, logger=None)\n",
    "```\n",
    " \n",
    "### 1.2.3 데이터셋 생성\n",
    "```python\n",
    "dataset_dict = get_dataset(config, config.algorithm, config.dataset, config.num_labels, config.num_classes, data_dir=config.data_dir)\n",
    "train_lb_loader = get_data_loader(config, dataset_dict['train_lb'], config.batch_size)\n",
    "train_ulb_loader = get_data_loader(config, dataset_dict['train_ulb'], int(config.batch_size * config.uratio))\n",
    "eval_loader = get_data_loader(config, dataset_dict['eval'], config.eval_batch_size)\n",
    "```\n",
    "\n",
    "### 1.2.4 학습\n",
    "```python\n",
    "trainer = Trainer(config, algorithm)\n",
    "trainer.fit(train_lb_loader, train_ulb_loader, eval_loader)\n",
    "```\n",
    "\n",
    "### 1.2.5 평가 및 prediction활용\n",
    "```python\n",
    "trainer.evaluate(eval_loader)\n",
    "\n",
    "y_pred, y_logits = trainer.predict(eval_loader)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 셋\n",
    "MixMatch, ReMixMatch, FixMatch, FlexMatch, SimMatch 순으로 수행되며, 최대한 hyperparameter는 통일하였으며, 각각의 구체적인 parameter는 config 폴더를 참고하면 된다.\n",
    "\n",
    "intro에서 설명한 대로 image domain에서의 본 방법론들의 성능은 이미 충분히 실험이 되고 분석이 수행되었기 때문에, 이번 실습에서는 특별히 NLP domain의 데이터를 활용해 실험을 수행하였다.  \n",
    "실험에서 활용한 데이터는 Amazon Review로 text classification에 활용되는 데이터이다.  \n",
    "\n",
    "각각 방법론에 대한 차이는 SSL 알고리즘만으로 통제하기 위해 두 데이터에 대한 다섯 가지 알고리즘 모두에서 사전 학습된 bert_base_uncased 모델을 통해 tokenizing을 수행하였다.\n",
    "\n",
    "- Amazon Review\n",
    "    - class: 5개 \n",
    "    - 전체 data: train-250000, dev-25000, test-650000\n",
    "<!-- - Yahoo Answers\n",
    "    - class: 10개\n",
    "    - 전체 data: train-500000, dev-50000, test-60000 -->\n",
    "\n",
    "추가로 각각의 방법론이 label data의 수에 따라 어떤 영향을 받는 지를 확인하기 위해 각각의 train data에서 labeled data의 수를 Amazon: (250, 1000)개 만큼 서로 다른 dataset을 만들어 실험 하였다.\n",
    "\n",
    "다양한 SSL 방법론 들은 data augmentation을 사용하는데, 본 데이터에서는 사전에 데이터 증강을 수행 해 놓은 결과를 데이터 셋 자체에 포함시켜 두었다.  \n",
    "그 예시의 형태는 다음과 같다.\n",
    "\n",
    "```python\n",
    "    \"0\": {\n",
    "        \"ori\": \"THIS is MUSIC at its BESTRob Dougan has done it. He's crafted musical perfection, or close to it anyway. I have finally found the music I've been waiting for my whole life in this album~~\",\n",
    "        \"aug_0\": \"THIS is MUSIC kurzfristig ist BestRob Dougan has done it all. He's superbly musical, or close to it. On that album - Rob D, are you a genius - I finally got the m~~\",\n",
    "        \"aug_1\": \"THIS is MUSIC at its - Um Rob Dougan has deed it. He's the crazy music definition, or close to it anyway. I find the station music I've waited my e~~\",\n",
    "        \"label\": \"4\" }\n",
    "```\n",
    "\n",
    "모델에서는 random으로 augmented data를 sampling하는 것으로 Stochastic data augmentation을 수행한다. 본 라이브러리 에서는 Amazon Review 각각 마다 두 가지의 augmentated data가 제공되어 최대 Augmentation의 수가 2로 제한된 상황이다. \n",
    "<!-- , Yahoo: (500, 2000) -->\n",
    "\n",
    "실험의 설계는 5개 model에 대해 Amazon Review의 labeled data가 250, 1000개 일때를 모두 실험 하므로, 총 5 x 2 = 10회의 실험이 수행된다. Titan RTX 3개에 병렬화 하여 multiprocessing_distributed 한 경우에도 실험 시간이 너무 길게 소요되어 현실적으로 학습 data는 50000개로 sampling 하였다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 sampling에 사용한 코드 이다.\n",
    "   ```python\n",
    "    import json\n",
    "    import random\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    with open(\"train.json\", \"r\") as st_json:\n",
    "        train_all = json.load(st_json)\n",
    "        \n",
    "    idx = random.sample(range(1,len(train_all)+1),50000)\n",
    "    idx =list(map(str, idx))\n",
    "    new_train = {}\n",
    "\n",
    "    new_key=0\n",
    "    for key, value in tqdm(train_all.items()): \n",
    "        if key in idx:\n",
    "            new_train[new_key] = value\n",
    "            new_key+=1\n",
    "\n",
    "    with open(\"new_tran.json\", 'w') as outfile:\n",
    "        json.dump(new_train, outfile)\n",
    "   ```\n",
    "결과적으로 다음과 같은 비율로 5개 class가 sampling 되었으며 [0.19846, 0.2022, 0.19914, 0.19932, 0.20088],  \n",
    "실제 model에 사용될 때는 oversampling하여 동일한 비율로 통일되었다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 실험 step by step\n",
    "\n",
    "1. 라이브러리에서 사용하는 python 버전이 3.8이므로 conda 혹은 docker container를 활용하여 해당 환경을 구성한다.\n",
    "    ```python\n",
    "    conda create --name usb python=3.8\n",
    "    ```\n",
    "\n",
    "2. repository clone \n",
    "   ```python\n",
    "   git clone https://github.com/microsoft/Semi-supervised-learning.git\n",
    "   ```\n",
    "3. install required packages\n",
    "   ```python\n",
    "   pip install -r requirements.txt\n",
    "   pip install semilearn\n",
    "   ```\n",
    "4. 데이터 다운로드 https://github.com/microsoft/Semi-supervised-learning/tree/main/preprocess\n",
    "   ```python\n",
    "   cd ../\n",
    "   mkdir data & cd data\n",
    "   wget https://wjdcloud.blob.core.windows.net/dataset/usbdata.tar.gz\n",
    "   tar -xvf usbdata.tar.gz\n",
    "   ```\n",
    "5. 실험의 목적에 맞는 config 파일을 만들기\n",
    "   본 튜토리얼 repository의 config 폴더 참고\n",
    "    <p align=\"center\">   <image src=\"./images/2022-12-27-17-16-53.png\" width=\"40%\"/>   </p>\n",
    "\n",
    "6. 학습 수행\n",
    "   ```python\n",
    "   python train.py --c config/fixmatch_amazon_review_200_0.yaml\n",
    "   ```\n",
    "\n",
    "7. 평가\n",
    "   ```python\n",
    "   python eval.py --dataset amazon_review_200 --num_classes 10 --load_path /PATH/TO/CHECKPOINT\n",
    "   ```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 실험 설정 (config)\n",
    "\n",
    "## 4.1 공통 설정\n",
    "- 병렬화: 한번의 batch size는 9개로 설정하고 3개의 gpu에서 각각 3개씩을 처리하도록 병렬화\n",
    "- 자연어 처리 backbone model: bert_base_uncased, max_length: 512\n",
    " <p align=\"center\">   <image src=\"./images/2022-12-27-21-37-59.png\" width=\"40%\"/>   </p>\n",
    "\n",
    "\n",
    "## 4.2 각 모델별 설정\n",
    "- MixMatch\n",
    "   ```YAML\n",
    "   mixup_alpha: 0.5\n",
    "   T: 0.5\n",
    "   ulb_loss_ratio: 100\n",
    "   unsup_warm_up: 0.4\n",
    "   mixup_manifold: True\n",
    "   ```\n",
    "\n",
    "- ReMixMatch\n",
    "   ```YAML\n",
    "   mixup_alpha: 0.75\n",
    "   T: 0.5\n",
    "   kl_loss_ratio: 0.5\n",
    "   ulb_loss_ratio: 1.5\n",
    "   rot_loss_ratio: 0.0\n",
    "   unsup_warm_up: 0.015625\n",
    "   mixup_manifold: True\n",
    "   ```\n",
    "- FixMatch\n",
    "   ```YAML\n",
    "   hard_label: True\n",
    "   T: 0.5\n",
    "   p_cutoff: 0.95\n",
    "   ulb_loss_ratio: 1.0\n",
    "   ```\n",
    "- FlexMatch\n",
    "   ```YAML\n",
    "   hard_label: True\n",
    "   T: 0.5\n",
    "   p_cutoff: 0.95\n",
    "   ulb_loss_ratio: 1.0\n",
    "   thresh_warmup: True\n",
    "   ```\n",
    "- SimMatch\n",
    "   ```YAML\n",
    "   T: 0.1\n",
    "   p_cutoff: 0.95\n",
    "   ulb_loss_ratio: 1.0\n",
    "   in_loss_ratio: 1.0\n",
    "   proj_size: 128\n",
    "   K: 256\n",
    "   da_len: 32\n",
    "   smoothing_alpha: 0.9\n",
    "   ```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 실험 결과\n",
    "\n",
    "## 5.1 50000개의 데이터 중 250개만 labeled 인경우\n",
    "eval dataset의 accuracy 기준으로 성능을 정리한 것이다. 첫 행의 Only labeled의 경우는 비교를 위해 250개의 데이터 만으로 학습을 수행 했을 때의 성능을 나타낸다.\n",
    "\n",
    "| model    | amazon_review_250       |\n",
    "| ---------- | --------- |\n",
    "| Only labeled | 0.35789  |\n",
    "| MixMatch  | 0.4014 |\n",
    "| ReMixMatch  | 0.2001 |\n",
    "| FixMatch  | 0.49324 |\n",
    "| FlexMatch  | 0.53192 |\n",
    "| SimMatch  | 0.49912 |\n",
    "* ReMixMatch의 경우 학습 과정에서 오류 발생\n",
    "\n",
    "기본적으로 단지 250개의 labeled 데이터 만을 사용했을 때보다는 성능이 향상되는 경향을 보이고 있고 FlexMatch의 경우가 가장 높은 성능을 보이고 있다. 그러나 각 방법론 사이에 성능 차이가 유의하지는 않는 것으로 보인다.  \n",
    "추가로 직접 실험한 환경 이외에 repository에서 제공하는 실험 결과를 첨부하면 다음과 같다. \n",
    "\n",
    "| model    | amazon_review_250       |\n",
    "| ---------- | -------------- |\n",
    "| Only labeled | 36.81±0.05 |\n",
    "| MixMatch  | 63.42±1.34 |\n",
    "| ReMixMatch  | 80.0±0.0 |\n",
    "| FixMatch  | 47.85±1.22|\n",
    "| FlexMatch  |  45.75±1.21 |\n",
    "| SimMatch  | 47.27±1.73 |\n",
    "\n",
    "MixMatch와 ReMixMatch의 성능은 대폭 증가되고, FixMatch, FlexMatch, SimMatch의 성능은 소폭 감소하였다. 이러한 결과는 우선 사용한 데이터의 수에서 차이가 나며, 세부적인 하이퍼파라미터의 차이에 의한 것일 것이다.  \n",
    "현재의 결과만 보면 MixMatch와 ReMixMatch의 경우가 조금 더 hyperparameter에 민감하다고 관찰이된다.\n",
    "\n",
    "## 5.2 50000개의 데이터 중 1000개만 labeled 인경우\n",
    "\n",
    "* 실험결과\n",
    "\n",
    "| model    | amazon_review_1000       |\n",
    "| ---------- | -------------- |\n",
    "| Only labeled | 0.3726 |\n",
    "| MixMatch  | 0.4058 |\n",
    "| ReMixMatch  | 0.2001 |\n",
    "| FixMatch  | 0.5414|\n",
    "| FlexMatch  |  0.55656 |\n",
    "| SimMatch  | 0.5424 |\n",
    "\n",
    "labeled data의 수가 증가한 만큼 labeled data만 사용한 경우의 성능이 약간 증가였다. 그 증가 폭에 비하면 FixMatch, FlexMatch, SimMatch의 성능 증가 폭이 유의미한 것으로 평가된다. \n",
    "\n",
    "* Reporting\n",
    "\n",
    "| model    | amazon_review_1000       |\n",
    "| ---------- | -------------- |\n",
    "| Only labeled | 36.88±0.19 |\n",
    "| MixMatch  | 69.97±7.09 |\n",
    "| ReMixMatch  | 80.0±0.0 |\n",
    "| FixMatch  | 43.73±0.45|\n",
    "| FlexMatch  |  43.14±0.82 |\n",
    "| SimMatch  | 43.09±0.5 |\n",
    "\n",
    "위 결과는 repository의 결과인데, 예상과는 다르게 labeled data의 수가 4배나 증가했음에도 큰 성능의 향상이 관찰되지 않는다. 유일하게 성능이 향상된 모델은 MixMatch로 본 모델이 50000개 중 1000개 비율, 즉, 0.02의 labeled 비율에 대해 성능이 향상된다는 것을 알 수 있다. 의외인 것은 FixMatch, FlexMatch, SimMatch의 경우 성능이 감소했단 것인데, 나머지 파라미터가 모두 동일했음에도 이러한 결과를 얻은 것은 의아하게 느껴진다. 이 같은 결과에 대한 원인을 추론해 보자면, 현재 사용하고 있는 데이터가 nlp text data로 본 방법론들이 제안된 image domain과 다른 성질을 가지기 때문으로 보인다. 현재는 모든 data를 bert를 통해 전처리 하는데, 이미 이 과정에서 각 데이터의 특징이 충분하게 추출되지 못하여 데이터의 증가가 확실한 정보의 증가로 이어지지 못할 수도 있다고 생각이된다. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

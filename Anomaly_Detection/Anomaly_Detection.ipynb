{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 인트로\n",
    "\n",
    "Anomaly Detection \n",
    "본 실습 파일은 우선 다음의 대표적이고 기본적인 Anomaly Detection 방법론 3가지를 다룬다.  \n",
    "-\tGaussian Density-based Anomaly Detection\n",
    "-\tMixture of Gaussians Density Estimation\n",
    "-\tAuto Encoder\n",
    "\n",
    "\n",
    "각각의 모델을 구현해보는 실습 이후에는 위 방법론들을 함께 사용하는 비교적 고도화된 모델 DAGMM(Zong, 2018) 모델을 다룬다.\n",
    "\n",
    "-\tDAGMM (Zong et al., ICLR 2018)\n",
    "\n",
    "각각의 모델에 대한 이론적 내용을 가볍게 설명하고, 실제 python 코드로 실험을 수행하는 과정으로 진행되며, 기본적으로 동일한 데이터에 대한 각 모델의 결과를 비교하는 과정을 포함한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 이론 및 코드 구현\n",
    "## 1.1\tAnomaly Detection\n",
    "Anomaly Detection은 이름에서 알 수 있듯이 Anomaly Data를 찾아내는 Task로 정상 데이터와 비정상 데이터를 구분해 내는 Task로 이해할 수 있다. 그렇다면 2 class Classification과 동일하게 느껴 질 수도 있는데, 두 Task는 다음과 같은 차이가 있다. \n",
    "\n",
    " <p align=\"center\">   <image src=\"./images/2022-11-16-23-39-00.png\" width=\"60%\"/>   </p>\n",
    "\n",
    "Classification의 경우 각 클래스 별 데이터가 존재하고, 데이터의 label을 활용하여 해당 class를 예측하도록 학습이 된다. 그러나 Anomaly Detection의 경우에는 학습 상황에서는 정상의 데이터만 존재한다는 가정에서 정상 데이터의 특징을 파악할 수 있도록 학습되고, Test 상황에서 학습 과정에서 보지 못한 Anomaly data를 구분하는 과정이다.  \n",
    "\n",
    "즉, two-class Classification의 경우 두가지 범주를 명시적으로 구분하는 것으로 한 class가 아니라면 반드시 다른 class인 상황이며, Anomaly Detection은 학습에 확인한 데이터와 동일한 성질의 데이터인지 아닌지 만을 판단하는 것이다. 즉, Anomaly라고 하더라도 엄밀히 말하면 불량 혹은 비정상 데이터인 것이 아니라 단지 학습에 보지 못한 새로운 성질의 데이터라고 하는 것이 옳다.  \n",
    "\n",
    "Anomaly Detection의 방식은 크게 두 가지로 구분할 수 있는데, 첫째로는 학습 데이터를 통해 정상 데이터의 특징을 파악하고, 새로운 데이터에 대해서 원래 데이터와의 차이 등을 Anomaly score로 계산하여 특정 threshold를 넘으면 Anomaly로 판단하는 경우가 있다. 이번에 실습으로 알아볼 4가지 방법론들은 모두 이 첫번째 case에 해당한다. 두 번 째로는 방법론이 normal/Anomaly 데이터를 구분하는 명시적인 경계면을 생성해 주는 경우이다. 1-SVM이나 SVDD 방법론이 이 경우에 해당한다.  \n",
    "\n",
    " <p align=\"center\">   <image src=\"./images/2022-11-16-23-39-27.png\" width=\"60%\"/>   </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이후의 모델 구현을 위한 라이브러리 및 데이터 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from numpy import genfromtxt\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score , average_precision_score\n",
    "from sklearn.metrics import precision_score, precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import tqdm\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time' 'V1' 'V2' 'V3' 'V4' 'V5' 'V6' 'V7' 'V8' 'V9' 'V10' 'V11' 'V12'\n",
      " 'V13' 'V14' 'V15' 'V16' 'V17' 'V18' 'V19' 'V20' 'V21' 'V22' 'V23' 'V24'\n",
      " 'V25' 'V26' 'V27' 'V28' 'Amount' 'Class']\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기: 본 데이터는 신용카드 거래 데이터로 다음과 같은 변수를 포함한다.\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 변수중 Class가 사기 거래인지 여부로 1이면 사기, 0이면 정상 거래를 의미한다.  \n",
    "# 즉, 이번 Anomaly Detection에서는 Class가 1인 데이터를 이상치로 판단한다.\n",
    "x = df['Class'].value_counts().index\n",
    "y = df['Class'].value_counts().values\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(x, y)\n",
    "plt.xticks(x, ['Normal', 'Fraud'])\n",
    "plt.title('Class Distribution')\n",
    "plt.show()\n",
    "\n",
    "# 편의를 위해 변수중 중요하다고 알려진 ['V3' 'V4' 'V7' 'V9' 'V10' 'V11' 'V12' 'V14' 'V16' 'V17' 'V18' 'Class']만 사용\n",
    "df = df[['V3', 'V4', 'V7', 'V9', 'V10', 'V11', 'V12', 'V14', 'V16' ,'V17', 'V18', 'Class']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 그래프를 보면 데이터에서 정상 거래와 사기거래의 비율이 매우 불균형한 것을 알 수 있다.\n",
    "즉, Classification이 아닌 Anomaly Detection으로 모델을 구현해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class가 0인 데이터만을 포함하는 학습데이터와 정상, 비정상 데이터가 섞인 테스트 데이터를 생성한다.\n",
    "df_normal=df[df['Class'] == 0]\n",
    "df_frud=df[df['Class'] == 1]\n",
    "df_normal = df_normal.sample(frac=1).reset_index(drop=True)\n",
    "train_data_size = int(len(df_normal)*0.8)\n",
    "train_df=df_normal[:train_data_size].drop(['Class'], axis=1)\n",
    "train_target=df_normal[:train_data_size]['Class']\n",
    "\n",
    "test_df=df_normal[train_data_size:]\n",
    "test_df=pd.concat([test_df, df_frud], axis=0,ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
    "test_target=test_df['Class']\n",
    "test_df=test_df.drop(['Class'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이후의 데이터 분석의 과정에서 데이터의 변수들이 모두 동일한 스케일을 갖도록 StandardScaler를 사용하여 스케일링한다.\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df)\n",
    "train_df = scaler.transform(train_df)\n",
    "test_df = scaler.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.09795249,  0.61259146,  6.58291625, ..., -2.30632139,\n",
       "         0.50935967,  2.40694181],\n",
       "       [ 0.86395855,  1.1164731 , -0.36455043, ...,  0.23101347,\n",
       "        -0.41152237,  0.13438191],\n",
       "       [-0.74565953, -0.92216026, -0.90387998, ..., -1.54051545,\n",
       "         1.41662554, -0.82279752],\n",
       "       ...,\n",
       "       [-0.22965871, -0.04522134,  0.3132716 , ...,  0.42754082,\n",
       "        -0.69142909, -0.89182143],\n",
       "       [ 0.50148564, -1.05070678, -1.44818478, ...,  0.08899021,\n",
       "         0.10186872,  1.20646265],\n",
       "       [ 0.87352953,  1.2130098 , -0.49362136, ..., -1.1997954 ,\n",
       "         0.78186833, -1.12355746]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.338509  ,  0.3909924 ,  0.45925715, ..., -0.04375216,\n",
       "         1.22324226,  0.07553191],\n",
       "       [-0.46162984, -0.32517525,  0.5831222 , ..., -0.52958264,\n",
       "        -0.39401647,  0.03589929],\n",
       "       [-1.61533929,  0.27687489,  0.24808873, ..., -0.55885102,\n",
       "         1.89674982, -0.6839821 ],\n",
       "       ...,\n",
       "       [-0.28753687, -0.37432762,  0.74953894, ...,  0.35428057,\n",
       "         0.63619227, -0.2533023 ],\n",
       "       [-0.75266307, -0.39233698, -0.45784117, ...,  0.75043416,\n",
       "        -1.2272715 , -0.09033819],\n",
       "       [-0.79191155, -1.78481424, -1.26177947, ..., -0.10020235,\n",
       "        -0.00678816,  0.47440001]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2\tGaussian Density-based Anomaly Detection\n",
    "\n",
    " <p align=\"center\">   <image src=\"./images/2022-11-16-23-39-51.png\" width=\"60%\"/>   </p>\n",
    "\n",
    "가장 첫 째로 살펴볼 방법론인 Gaussian Density-based Anomaly Detection은 정상의 학습데이터가 기저에서 Gaussian distribution을 따른다는 가정에서 데이터가 생성되는 데 사용된 분포를 추정하고, 새로운 데이터가 해당 분포에서 생성될만 한지를 통해 Anomaly Detection을 수행한다. 한마디로 하자면 다음과 같다. \"학습 데이터를 보니 이 데이터들은 평균 0이고 분산이 10인 Gaussian 분포를 따르는 거 같은데, 새로운 데이터의 값이 10000이니 이건 같은 분포에서 생성된 데이터는 아니겠다. 이건 이상치네!\"  \n",
    "\n",
    "실제 과정은 다음과 같이 1)Gaussian parameter 추정, 2) test 데이터의 Anomaly Score 산출로 이루어진다.  \n",
    " \n",
    "1) Gaussian parameter 추정  \n",
    "  : 학습데이터에 대해 Maximum Likelihood Estimation을 수행해 단순 계산으로 구한다.  \n",
    "\n",
    " <p align=\"center\">   <image src=\"./images/2022-11-16-23-40-08.png\" width=\"60%\"/>   </p>\n",
    "\n",
    "2) test 데이터의 Anomaly Score 산출  \n",
    "  : 위에서 찾은 Gaussian parameter를 가지는 Gaussian Distribution에 대해 각 데이터의 확률을 계산하고, 그 확률이 특정 threshold 보다 작다면 이상치로 판단한다.\n",
    "\n",
    " <p align=\"center\">   <image src=\"./images/2022-11-16-23-40-18.png\" width=\"60%\"/>   </p>\n",
    "\n",
    "\n",
    "장점  \n",
    "  \n",
    "수식에서 보았듯이 쉽게 빠르게 연산이 가능한 방법론이며, 분포상의 확률이라는 직관적인 Anomaly Score를 제공한다. 또한 threshold를 조절하는 것을 통해 상황에 맞게 대응이 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Density-based Anomaly Detection 코드 구현\n",
    "\n",
    "#  1. Gaussian parameters 구하기\n",
    "def estimateGaussian(X):\n",
    "    mu = np.mean(X, axis=0)\n",
    "    sigma = np.cov(X.T)\n",
    "    return mu, sigma\n",
    "    \n",
    "#  2. Gaussian parameters를 이용하여 Anomaly Score 구하기\n",
    "def multivariateGaussian(X, mu, sigma):\n",
    "    p = multivariate_normal(mean=mu, cov=sigma)\n",
    "    return p.pdf(X)\n",
    "\n",
    "#  3. Anomaly Score를 이용하여 Threshold 구하기\n",
    "def selectThreshold(target, p):\n",
    "    bestEpsilon = 0\n",
    "    bestF1 = 0\n",
    "    F1 = 0\n",
    "    stepsize = (max(p) - min(p)) / 1000\n",
    "    for epsilon in np.arange(min(p), max(p), stepsize):\n",
    "        predictions = (p < epsilon)\n",
    "        # class 간 불균형있고, 범주 중 사기거래 범주에 더욱 중요한 상황이므로 F1 score를 사용한다.\n",
    "        F1 = f1_score(np.array(target), predictions)\n",
    "        if F1 > bestF1:\n",
    "            bestF1 = F1\n",
    "            bestEpsilon = epsilon\n",
    "    return bestF1, bestEpsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu: [-1.32454373e-17  2.51788265e-17 -3.37383780e-18  2.25547305e-17\n",
      "  1.24956955e-17  8.24715906e-18  3.87366562e-18 -6.90387179e-18\n",
      " -2.16800318e-17 -4.77960355e-18 -1.78063662e-17]\n",
      "sigma: [[ 1.0000044   0.0384964  -0.08239973 -0.03465707 -0.0783181   0.04426141\n",
      "  -0.08098006 -0.08151095 -0.06567352 -0.12049583 -0.03820431]\n",
      " [ 0.0384964   1.0000044   0.04003199  0.01807907  0.04166163 -0.02847871\n",
      "   0.04820642  0.05369074  0.03887926  0.06845537  0.02263542]\n",
      " [-0.08239973  0.04003199  1.0000044  -0.03443295 -0.08261571  0.04708865\n",
      "  -0.0902637  -0.08304946 -0.06709992 -0.14139273 -0.05025419]\n",
      " [-0.03465707  0.01807907 -0.03443295  1.0000044  -0.03552605  0.02410527\n",
      "  -0.04123797 -0.04103343 -0.03264606 -0.06306157 -0.02085331]\n",
      " [-0.0783181   0.04166163 -0.08261571 -0.03552605  1.0000044   0.05127886\n",
      "  -0.09412433 -0.09524189 -0.07651056 -0.14325681 -0.04688237]\n",
      " [ 0.04426141 -0.02847871  0.04708865  0.02410527  0.05127886  1.0000044\n",
      "   0.06264554  0.06702706  0.04740946  0.08522583  0.02803873]\n",
      " [-0.08098006  0.04820642 -0.0902637  -0.04123797 -0.09412433  0.06264554\n",
      "   1.0000044  -0.11798592 -0.08758245 -0.16449229 -0.05562884]\n",
      " [-0.08151095  0.05369074 -0.08304946 -0.04103343 -0.09524189  0.06702706\n",
      "  -0.11798592  1.0000044  -0.08924616 -0.16095722 -0.05128485]\n",
      " [-0.06567352  0.03887926 -0.06709992 -0.03264606 -0.07651056  0.04740946\n",
      "  -0.08758245 -0.08924616  1.0000044  -0.1422528  -0.048305  ]\n",
      " [-0.12049583  0.06845537 -0.14139273 -0.06306157 -0.14325681  0.08522583\n",
      "  -0.16449229 -0.16095722 -0.1422528   1.0000044  -0.09319601]\n",
      " [-0.03820431  0.02263542 -0.05025419 -0.02085331 -0.04688237  0.02803873\n",
      "  -0.05562884 -0.05128485 -0.048305   -0.09319601  1.0000044 ]]\n"
     ]
    }
   ],
   "source": [
    "# 정의한 함수를 통해 데이터의 변수에 따른 Gaussian parameters를 구한다.\n",
    "mu, sigma = estimateGaussian(train_df)\n",
    "\n",
    "print(f'mu: {mu}')\n",
    "print(f'sigma: {sigma}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 데이터의 발생확률 p: [1.40797931e-06 1.54442529e-05 1.33019841e-07 ... 9.77796229e-06\n",
      " 9.61537448e-06 1.13357318e-07], 데이터의 개수: 57355\n"
     ]
    }
   ],
   "source": [
    "# 다음으로 구한 Gaussian parameters를 이용하여 각 데이터가 다변량 가우시안 분포에 대해서 발생할 확률을 구한다.\n",
    "p_test = multivariateGaussian(test_df,mu,sigma)\n",
    "print(f'각 데이터의 발생확률 p: {p}, 데이터의 개수: {len(p)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.9008e+04, 8.3590e+03, 5.0430e+03, 2.2740e+03, 1.2270e+03,\n",
       "        6.9800e+02, 4.0700e+02, 2.2900e+02, 1.0500e+02, 5.0000e+00]),\n",
       " array([0.00000000e+00, 4.15285173e-06, 8.30570347e-06, 1.24585552e-05,\n",
       "        1.66114069e-05, 2.07642587e-05, 2.49171104e-05, 2.90699621e-05,\n",
       "        3.32228139e-05, 3.73756656e-05, 4.15285173e-05]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fscore: 0.08507042253521127, ep: 4.1528517343356454e-08\n"
     ]
    }
   ],
   "source": [
    "# 다음으로는 현재 계산된 p값 즉, Anomaly Score를 어느 기준에서 비정상 데이터로 판단할지 threshold를 구한다.\n",
    "fscore, ep= selectThreshold(test_target,p_test)\n",
    "print(f'fscore: {fscore}, ep: {ep}')\n",
    "\n",
    "# 본 데이터와 같이 복잡한 데이터의 경우, 기본적인 Gaussian Density-based Anomaly Detection에는 좋은 성능을 보이지 못하고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3\tMixture of Gaussians Density Estimation\n",
    "앞서 설명한 Gaussian Density-based Anomaly Detection 방법론의 경우 쉽게 적용 가능하다는 것이 장점이지만, 다소 세상을 너무 쉽게 본 경향이 있다. 과연 실제 현실의 데이터가 하나의 정규분포로부터 발생하였을까? 세상의 다양한 현상들이 크게 보면 정규 분포를 따르는 경향이 있는 것은 분명하지만, 확실하게 다수의 분포로부터 데이터가 발생했다고 보는 것이 더 정확한 경우는 많이 있다. 간단한 예시를 들어보면 사람의 신장에 대한 분포를 살펴본다면 나름대로 Gaussian 분포를 따를 수도 있지만, 성별에 따라 조금 다른 분포를 보일 수 있다는 건 쉽게 생각할 수 있다. 또 만약 국가가 달라진다면 국민들의 키가 키기로 유명한 북유럽 국가 국민들의 키 분포와 우리나라의 키 분포가 과연 하나의 단봉(분포의 모양이 봉우리가 하나라는 의미) Gaussian 분포를 이룰까? 이런 상황을 분석하기 위해서 우리는 여러 개의 Gaussian 분포를 선형 결합한 Mixture of Gaussians를 사용하곤 한다. 이 아이디어를 Anomaly Detection에 적용한 것이 이번에 알아볼 Mixture of Gaussians Density Estimation 방법론이다.  \n",
    "\n",
    " <p align=\"center\">   <image src=\"./images/2022-11-16-23-40-36.png\" width=\"60%\"/>   </p>\n",
    "\n",
    "데이터에 대해 추정하는 분포가 단봉이 아니라 multi-mode(다봉)라는 것만 제외한다면 Anomaly Detection의 아이디어는 동일하다. 데이터를 통해 추정한 분포에 대해서 새로운 test 데이터가 발생할 확률이 작다면 이상치로 판단하는 것이다.  \n",
    "\n",
    "가장 큰 차이가 발생하는 부분은 분포의 파라미터(모수, parameter)를 추정하는 과정이 단봉이었을 때와는 다르게 한 번에 최적화가 불가능하고 EM알고리즘을 통해 순차적으로 찾아가야 한다는 것이다. 기존의 단봉 상황에선 모든 데이터가 하나의 가우시안 분포로부터 기인했다는 가정을 하기 때문에 모든 데이터를 사용하여 Maximum Likely Estimation을 통해 단순 계산으로 파라미터를 구할 수 있었다. 그러나 현재 multi-mode 상황에서는 어떤 데이터가 어떤 mode로부터 생성되었는지를 알지 못해, 어떤 데이터를 통해 어떤 mode의 파라미터를 계산해야 하는지 알 수가 없다. 또한 각각의 mode가 결합되는 비율도 알 수가 없다. EM 알고리즘은 Expectation–maximization algorithm의 줄임 말로 지금처럼 한 번에 최적화가 불가능한 상황에서 Expectation, maximization 과정을 반복하는 것으로 최적화를 수행하는 대표적인 방법이다.  \n",
    "\n",
    "각각의 과정은 다음과 같은 역할을 수행한다.  \n",
    "- Expectation: 현재 시점의 파라미터를 사용해 어떤 데이터가 어떤 가우시안 분포에 할당되어야 최대 likelihood를 가지는 지를 통해 데이터를 mode에 할당  \n",
    "\n",
    " <p align=\"center\">   <image src=\"./images/2022-11-16-23-41-09.png\" width=\"60%\"/>   </p>\n",
    "\n",
    "- Maximization: 현재 할당된 데이터를 기분으로 likelihood를 최대화하도록 각 가우시안 분포의 파라미터 업데이트  \n",
    "\n",
    " <p align=\"center\">   <image src=\"./images/2022-11-16-23-41-30.png\" width=\"60%\"/>   </p>\n",
    " \n",
    "즉, 최적화의 과정을 정리하면 다음과 같다.  \n",
    "\n",
    "1)\t가우시안 파라미터 랜덤 초기화  \n",
    "2)\tExpectation  \n",
    "3)\tMaximization  \n",
    "4)\tE-M 과정 정해진 수만큼 반복  \n",
    "추가로 전체적인 수식은 다음과 같다.  \n",
    "\n",
    " <p align=\"center\">   <image src=\"./images/2022-11-16-23-41-49.png\" width=\"60%\"/>   </p>\n",
    "\n",
    "추가로 연산 효율을 위해 다양한 형태의 공분산 행렬 사용 가능하며 공분산 행렬 형태에 따라 다양한 Mixture of Gaussians 형태가 발생한다.  \n",
    "\n",
    " <p align=\"center\">   <image src=\"./images/2022-11-16-23-42-03.png\" width=\"60%\"/>   </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixture of Gaussians Density Estimation 코드 구현\n",
    "# 본 방법론의 경우도 Gaussian Density-based Anomaly Detection과 마찬가지로 Gaussian parameters를 구하는 과정이 필요하다.\n",
    "# 다만, 본 방법론은 Gaussian parameters를 구하는 과정에서 EM 알고리즘을 사용한다.\n",
    "\n",
    "# 1. M-step Gaussian parameters 구하기\n",
    "# 먼저 파라미터 초기화를 위한 함수를 정의한다.\n",
    "\n",
    "class theta():\n",
    "    def __init__(self, pi, mu, Sigma):\n",
    "        self.pi = pi\n",
    "        self.mu = mu\n",
    "        self.Sigma = Sigma\n",
    "\n",
    "# 다음으로 각각의 파라미터를 계산하기위한 함수를 정의한다.\n",
    "def get_gamma(theta_val, X, K):\n",
    "    gamma = np.empty((0,K))\n",
    "\n",
    "    for n in range(len(X)):\n",
    "        gamma_n = np.array([])\n",
    "\n",
    "        for k in range(K):\n",
    "            denom_elem = np.array([])\n",
    "            for j in range(K):\n",
    "                dist_j = multivariate_normal(\n",
    "                    mean=theta_val.mu[j],\n",
    "                    cov=theta_val.Sigma[j])\n",
    "                denom_elem = np.append(denom_elem, theta_val.pi[j] * dist_j.pdf(X[n]))\n",
    "            denom = denom_elem.sum()\n",
    "\n",
    "            dist_k = multivariate_normal(\n",
    "                mean=theta_val.mu[k],\n",
    "                cov=theta_val.Sigma[k])\n",
    "            numer = theta_val.pi[k] * dist_k.pdf(X[n])\n",
    "\n",
    "            gamma_n = np.append(gamma_n, numer / denom)\n",
    "\n",
    "        gamma = np.vstack((gamma, gamma_n))\n",
    "\n",
    "    return gamma\n",
    "\n",
    "def get_mu(gamma, X, K):\n",
    "    mu_new = np.zeros((K,X.shape[1]), dtype=np.float64)\n",
    "\n",
    "    for k in range(K):\n",
    "        denom = sum(gamma[n][k] for n in range(len(X)))\n",
    "        numer_x = sum(gamma[n][k] * X[n][0] for n in range(len(X)))\n",
    "        mu_new[k][0] = numer_x / denom\n",
    "        numer_y = sum(gamma[n][k] * X[n][1] for n in range(len(X)))\n",
    "        mu_new[k][1] = numer_y / denom\n",
    "\n",
    "    return mu_new\n",
    "\n",
    "def get_sigma(gamma, mu_new, X, K):\n",
    "    Sigma_new = np.empty((0,X.shape[1],X.shape[1]))\n",
    "\n",
    "    for k in range(K):\n",
    "        denom = sum(gamma[n][k] for n in range(len(X)))\n",
    "        numer = np.zeros((X.shape[1],X.shape[1]), dtype=np.float64)\n",
    "        for n in range(len(X)):\n",
    "            sub = np.subtract(X[n], mu_new[k])\n",
    "            sub = np.array([sub])\n",
    "            sub_t = sub.transpose()\n",
    "            numer = numer + gamma[n][k] * np.matmul(sub_t, sub)\n",
    "        Sigma_new = np.vstack((Sigma_new, [numer / denom]))\n",
    "\n",
    "    return Sigma_new\n",
    "\n",
    "def get_pi(gamma, X, K):\n",
    "    pi_new = np.array([])\n",
    "\n",
    "    for k in range(K):\n",
    "        pi_new = np.append(\n",
    "            pi_new,\n",
    "            sum(gamma[n][k] for n in range(len(X))) / len(X))\n",
    "\n",
    "    return pi_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23664/2896471356.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#파라미터 초기화\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m theta_old = theta(\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirichlet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'X'"
     ]
    }
   ],
   "source": [
    "cov=np.ones(K*train_df.shape[1]*train_df.shape[1]).reshape(K,train_df.shape[1],train_df.shape[1])\n",
    "for i in range(K):\n",
    "    cov[i]=np.stack(np.cov(train_df, rowvar=False), axis=0)\n",
    "\n",
    "# 가우시안의 갯수 K는 하이퍼 파라미터이므로 미리 정의해 준다. \n",
    "K = 3\n",
    "\n",
    "#파라미터 초기화\n",
    "theta_old = theta(\n",
    "    pi=np.random.dirichlet(np.ones(K),size=1)[0],\n",
    "    mu=np.random.random(K*train_df.shape[1]).reshape(K,train_df.shape[1]),\n",
    "    Sigma=cov,\n",
    "    X=train_df,\n",
    "    K=K\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi:[0.54923453 0.32823426 0.1225312 ], mu:[[ 0.1203064   0.33999383  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.18869778 -0.45188965  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [-1.08800239 -0.25301551  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]], Sigma:[[[ 0.63361202  0.0116806  -0.03744429 -0.07651651 -0.05846848\n",
      "    0.03507806 -0.09539221  0.02949058 -0.0099766  -0.03844385\n",
      "   -0.03500031]\n",
      "  [ 0.0116806   0.80824855 -0.08610826 -0.27617699  0.42966475\n",
      "   -0.06654013 -0.07440725  0.01959957  0.09112187  0.03252597\n",
      "    0.01509151]\n",
      "  [-0.03744429 -0.08610826  0.2949155  -0.17897744 -0.0933303\n",
      "   -0.07408895  0.00558935 -0.02969472 -0.06390211 -0.0143603\n",
      "   -0.03955604]\n",
      "  [-0.07651651 -0.27617699 -0.17897744  0.78184135 -0.30973886\n",
      "    0.05932896 -0.26631692  0.20460743 -0.05444915  0.09735953\n",
      "    0.02457033]\n",
      "  [-0.05846848  0.42966475 -0.0933303  -0.30973886  0.45381231\n",
      "   -0.04612243  0.02610707  0.06782874  0.07605795 -0.13729918\n",
      "   -0.01468704]\n",
      "  [ 0.03507806 -0.06654013 -0.07408895  0.05932896 -0.04612243\n",
      "    0.94010929  0.00973156  0.26666968  0.03187229  0.17579761\n",
      "    0.10053992]\n",
      "  [-0.09539221 -0.07440725  0.00558935 -0.26631692  0.02610707\n",
      "    0.00973156  1.18785171 -0.47960787 -0.1516212  -0.29562648\n",
      "   -0.16708587]\n",
      "  [ 0.02949058  0.01959957 -0.02969472  0.20460743  0.06782874\n",
      "    0.26666968 -0.47960787  0.80936946 -0.04980201 -0.15699058\n",
      "   -0.07611241]\n",
      "  [-0.0099766   0.09112187 -0.06390211 -0.05444915  0.07605795\n",
      "    0.03187229 -0.1516212  -0.04980201  0.51618284 -0.27403831\n",
      "    0.30471557]\n",
      "  [-0.03844385  0.03252597 -0.0143603   0.09735953 -0.13729918\n",
      "    0.17579761 -0.29562648 -0.15699058 -0.27403831  0.7900225\n",
      "   -0.1458687 ]\n",
      "  [-0.03500031  0.01509151 -0.03955604  0.02457033 -0.01468704\n",
      "    0.10053992 -0.16708587 -0.07611241  0.30471557 -0.1458687\n",
      "    0.69377529]]\n",
      "\n",
      " [[ 0.77187168  0.07410967  0.16874756  0.26334433 -0.03145898\n",
      "    0.05111411 -0.0891813  -0.41308815 -0.05063401  0.0448421\n",
      "   -0.06402201]\n",
      "  [ 0.07410967  0.85239944 -0.27517365  0.34511275 -0.09626431\n",
      "   -0.16118897  0.25047702  0.10437404 -0.06486895  0.11436505\n",
      "    0.11286749]\n",
      "  [ 0.16874756 -0.27517365  2.29495263  0.43469855  0.35417012\n",
      "    0.28146751 -0.44976059 -0.5062628  -0.21355818 -0.42737505\n",
      "   -0.27929311]\n",
      "  [ 0.26334433  0.34511275  0.43469855  1.35133053 -0.33982275\n",
      "   -0.01363412  0.16694321 -0.26637352  0.15990746 -0.27842629\n",
      "   -0.13750752]\n",
      "  [-0.03145898 -0.09626431  0.35417012 -0.33982275  1.01579724\n",
      "    0.2131862  -0.43072799 -0.41109641 -0.25438693  0.01588544\n",
      "   -0.01292523]\n",
      "  [ 0.05111411 -0.16118897  0.28146751 -0.01363412  0.2131862\n",
      "    0.96924774  0.09964153  0.02937877  0.05954616 -0.04888726\n",
      "   -0.12305117]\n",
      "  [-0.0891813   0.25047702 -0.44976059  0.16694321 -0.43072799\n",
      "    0.09964153  0.74684181  0.20123334 -0.04078423 -0.05580542\n",
      "    0.13327931]\n",
      "  [-0.41308815  0.10437404 -0.5062628  -0.26637352 -0.41109641\n",
      "    0.02937877  0.20123334  0.7444705   0.05892088  0.04630862\n",
      "    0.23039644]\n",
      "  [-0.05063401 -0.06486895 -0.21355818  0.15990746 -0.25438693\n",
      "    0.05954616 -0.04078423  0.05892088  1.36184717 -0.26065476\n",
      "   -0.60307133]\n",
      "  [ 0.0448421   0.11436505 -0.42737505 -0.27842629  0.01588544\n",
      "   -0.04888726 -0.05580542  0.04630862 -0.26065476  0.66971094\n",
      "   -0.22737167]\n",
      "  [-0.06402201  0.11286749 -0.27929311 -0.13750752 -0.01292523\n",
      "   -0.12305117  0.13327931  0.23039644 -0.60307133 -0.22737167\n",
      "    1.34644818]]\n",
      "\n",
      " [[ 2.49177886 -0.95580528 -0.6376118  -0.25532858 -0.10408898\n",
      "   -0.35432256 -0.5155011  -0.46870112 -0.74698687 -0.68968508\n",
      "    0.25179474]\n",
      "  [-0.95580528  1.46671796  0.72136508  0.1372048   0.24962035\n",
      "    0.35195446 -0.0698707  -0.35093322  0.39930602  0.36099717\n",
      "   -0.3538472 ]\n",
      "  [-0.6376118   0.72136508  1.8713708   0.63154063  0.70463796\n",
      "    0.47238049 -0.21650085 -0.65239975  0.15013627 -0.60179778\n",
      "   -0.73278625]\n",
      "  [-0.25532858  0.1372048   0.63154063  1.78359973  1.89956886\n",
      "    0.39336175 -0.10642811 -1.04950951 -0.04450787 -0.28895356\n",
      "   -0.08280577]\n",
      "  [-0.10408898  0.24962035  0.70463796  1.89956886  3.65527392\n",
      "    0.61016097 -0.20318006 -1.37914688 -0.42662426 -0.4383806\n",
      "   -0.28900548]\n",
      "  [-0.35432256  0.35195446  0.47238049  0.39336175  0.61016097\n",
      "    0.99523679  0.04012807 -0.71561078  0.31665507  0.32827364\n",
      "   -0.04284389]\n",
      "  [-0.5155011  -0.0698707  -0.21650085 -0.10642811 -0.20318006\n",
      "    0.04012807  1.07922186  0.89712482  0.13794168  0.24552429\n",
      "    0.13440249]\n",
      "  [-0.46870112 -0.35093322 -0.65239975 -1.04950951 -1.37914688\n",
      "   -0.71561078  0.89712482  3.81889681 -0.41603723 -1.08320363\n",
      "   -0.49763719]\n",
      "  [-0.74698687  0.39930602  0.15013627 -0.04450787 -0.42662426\n",
      "    0.31665507  0.13794168 -0.41603723  2.12389056  0.75041773\n",
      "   -0.28029212]\n",
      "  [-0.68968508  0.36099717 -0.60179778 -0.28895356 -0.4383806\n",
      "    0.32827364  0.24552429 -1.08320363  0.75041773  3.27694602\n",
      "    0.8850577 ]\n",
      "  [ 0.25179474 -0.3538472  -0.73278625 -0.08280577 -0.28900548\n",
      "   -0.04284389  0.13440249 -0.49763719 -0.28029212  0.8850577\n",
      "    1.44204682]]]\n"
     ]
    }
   ],
   "source": [
    "# 빠른 학습을 위해 데이터를 샘플링한다.\n",
    "train_df_sample = train_df[0:1000]\n",
    "\n",
    "# EM 알고리즘 수행\n",
    "for loop in range(5):\n",
    "    print(f\"Running iteration {loop + 1} ...\", end=\"\\r\")\n",
    "    # Get gamma\n",
    "    l_gamma = get_gamma(theta_old, train_df_sample,K)\n",
    "    # Get new mu\n",
    "    l_mu_new = get_mu(l_gamma,train_df_sample,K)\n",
    "    # Get new sigma\n",
    "    l_sigma_new = get_sigma(l_gamma, l_mu_new,train_df_sample,K)\n",
    "    # Get new pi\n",
    "    l_pi_new = get_pi(l_gamma,train_df_sample,K)\n",
    "    # Replace theta\n",
    "    theta_old = theta(\n",
    "        pi=l_pi_new,\n",
    "        mu=l_mu_new,\n",
    "        Sigma=l_sigma_new\n",
    "    )\n",
    "print(f\"pi:{theta_old.pi}, mu:{theta_old.mu}, Sigma:{theta_old.Sigma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3,), (3, 11), (3, 11, 11))"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습된 파라미터를 받아서 테스트 데이터에 대한 예측값을 구하는 함수를 정의한다.\n",
    "\n",
    "pi=theta_old.pi\n",
    "mu=theta_old.mu\n",
    "Sigma=theta_old.Sigma\n",
    "\n",
    "pi.shape, mu.shape, Sigma.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0000044 ,  0.0384964 , -0.08239973, -0.03465707, -0.0783181 ,\n",
       "        0.04426141, -0.08098006, -0.08151095, -0.06567352, -0.12049583,\n",
       "       -0.03820431])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pi[0]*multivariate_normal(mean=mu[0], cov=sigma[0])+pi[1]*multivariate_normal(mean=mu[1], cov=sigma[1])+pi[2]*multivariate_normal(mean=mu[2], cov=sigma[2])\n",
    "prob=p.pdf(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob=p.pdf(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4\tAuto Encoder\n",
    "우선 Auto-Encoder 자체에 대해 이야기 해보자. Auto-Encode란 입력과 출력이 동일한 Encoder & Decoder 구조의 인공신경망이다.\n",
    "\n",
    " <p align=\"center\">   <image src=\"./images/2022-11-16-23-58-39.png\" width=\"60%\"/>   </p>\n",
    "\n",
    "위 그림에서도 확인이 가능한데, 모델의 input과 output이 모두 X로 동일하다. 또한 아래의 그림을 보면 입력과 출력의 크기가 동일한 것에 비해 중간의 latent Vector는 더 적은 차원을 가진 것을 확인 할 수 있다.\n",
    "\n",
    " <p align=\"center\">   <image src=\"./images/2022-11-17-00-01-14.png\" width=\"60%\"/>   </p>\n",
    "\n",
    "이는 입력 변수보다 적은 차원의 Latent Space를 거치는 것으로 정보의 축약을 수행하는 것으로, 모델은 이처럼 입력을 축약하는 Mapping 과정과 그를 다시 복원하는 de-mapping 과정을 거친다. 모델의 학습은 입력과 출력이 최대한 동일해지도록 수행되며, 이 과정을 통해 모델은 입력 데이터를 보다 확실히 이해할 수 있게된다.\n",
    "\n",
    " <p align=\"center\">   <image src=\"./images/2022-11-17-00-05-29.png\" width=\"60%\"/>   </p>\n",
    "\n",
    "이런 Auto-Encoder의 활용은 크게 두가지가 있는데, 첫 째로는 데이터 차원 축소 도구로써 역할을 수행하여 latent vector가 다른 ML 모델의 input으로 사용되도록 하는 경우이다. 두 번째는 이번 실습의 주제인 Anomaly Detection을 수행하는 것인데, 기본적인 Anomaly detection 학습의 과정과 동일하게 모델은 정상 데이터만을 통해 학습이 되므로 모델은 정상 데이터를 압축, 복원하는 방법을 익히게 된다. 즉, 새로이 비정상 데이터가 들어온다면 모델을 통과한 결과 제대로 복원되지 못할 것이고, Reconstruction Loss가 큰게 나타나게 된다.\n",
    "\n",
    " <p align=\"center\">   <image src=\"./images/2022-11-17-02-12-04.png\" width=\"60%\"/>   </p>\n",
    "\n",
    "Auto-Encoder의 장점은 복원되는 정도가 어느 위치에서 영향을 받는지 확인이 가능하다는 점이 있는데, 이는 위 그림에서 잘 나타난다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto Encoder 코드 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 DAGMM\n",
    "마지막으로 기본적인 방법론들에서 조금 더 나아가 살펴볼 모델은 앞서 설명한 Mixture of Gaussians Density Estimation과 Auto-Encoder를 함께 사용하는 DEEP AUTOENCODING GAUSSIAN MIXTURE MODEL 이다. 본 방법론은 DEEP AUTOENCODING GAUSSIAN MIXTURE MODEL FOR UNSUPERVISED ANOMALY DETECTION (Zong et al., ICLR 2018) 논문에서 제안된 방식으로 전체적인 구조는 아래와 같다.\n",
    "\n",
    " <p align=\"center\">   <image src=\"./images/2022-11-17-02-20-58.png\" width=\"60%\"/>   </p>\n",
    "\n",
    "그림에서 알 수 있듯이 Auto-Encoder로 구성된 Compression Network와 Mixture of Gaussians Density Estimation의 Estimation역할을 수행하는 Estimation Network로 구성되는 모델로, Auto-Encoder의 또 다른 활용법인 차원축소를 통해 얻은 저차원의 결과를 Mixture of Gaussians Density Estimation에 활용한다고 보면 된다.  \n",
    "\n",
    "하나 짚고 넘어갈 점은 일전 Mixture of Gaussians Density Estimation를 설명할 때, EM 알고리즘은 Expectation & Maximization의 약자라고 설명하였으나 본 논문에서는 Estimation으로 용어를 사용하고 있다. 실제로 의미가 비슷하기도 하고 다양한 출처에서 둘을 혼용하고 있으니 참고바란다.  \n",
    "\n",
    "DAGMM의 지적하는 기존 방법론의 문제점은 바로 이 EM 알고리즘을 통해 최적화되야 한다는 점으로, 본 방법론은 end-to-end 학습이 가능한 구조이다. Auto-Encoder가 사용되는 부분은 차원의 축소를 담당하는 것으로 이상치 탐지에는 비교적 직접적으로 사용되지는 않으며 핵심은 Estimation Network에 있다. 이 Estimation Network는 MLN이 반복되고 마지막에 Softmax layer가 있는 구조로 Compression Network의 결과를 받아 최종적으로 각각의 데이터 포인트가 어떤 가우시안 mode에 포함될지를 확률의 형태로 산출해 준다. 기존의 GMM에 EM 알고리즘이 필요했던 이유는 각 데이터가 어떤 mode에 속하는지 결정이 되어야 가우시안의 파라미터를 계산할 수가 있고, 동시에 각 가우시안의 파라미터가 결정이 되어있어야 데이터들의 likelyhood를 계산 할 수 있기 때문에 동시에 최적화가 불가능 하다는 것이었다. 그러나 DAGMM 처럼 모델의 output에 직접적으로 각 데이터 포인트가 어떤 mode에 속하는지를 확률로 알려준다면 그를 활용해 바로 가우시안 분포의 파라미터 추정할 수가 있고 최종적으로 Objective function 최적화를 수행할 수가 있다.\n",
    "\n",
    "전체적인 Process와 계산식은 다음과 같다.\n",
    "\n",
    " <p align=\"center\">   <image src=\"./images/2022-11-17-02-34-10.png\" width=\"60%\"/>   </p>\n",
    "\n",
    "특징적인 부분만을 일부 더 살펴보면 Compression Network에서는 일반적인 차원 축소의 결과로 latent vector만을 사용하는 것과는 다르게, Auto-Encoder 입력과 출력 사이의 cos similarity와 L2 norm을 계산한 것을 concatenation하여 사용한다는 것이다.  \n",
    "\n",
    "또 Loss를 보면 크게 세 가지 부분으로 구분이 되는데, 순서대로 Auto-Encoder 학습을 담당하는 Reconstruction error, Likelihood와 유사하게 작동하여 input을 관측할 확률이 높아지도록 하는 Sample energy Function이 있으며, 마지막으로는 GMM과 동일하게 특정한 position에서 data의 발생확률이 지나치게 높게 학습되는 특이점 문제를 방지하기 위해 공분산 행렬의 대각의 값들이 0이 되는 것을 방지하는 Penalized Diagonal Entries term이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAGMM 코드 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 코드 실습\n",
    "## 2.1 데이터 load\n",
    "## 2.2 Gaussian Density-based Anomaly Detection\n",
    "## 2.3 Mixture of Gaussians Density Estimation\n",
    "## 2.4 Auto Encoder\n",
    "## 2.5 DAGMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 동일한 데이터에 대한 모델 비교 실험 및 결과 분석석\n",
    "## 3.1 각 모델의 하이퍼 파라미터 개수 비교\n",
    "## 3.2 End-to-end 여부\n",
    "## 3.3 단순 성능\n",
    "## 3.4 실행 시간\n",
    "## 3.5 Anomaly Detection threshold에 따른 민감성, robustness, AUROC\n",
    "\n",
    "Reference\n",
    "DEEP AUTOENCODING GAUSSIAN MIXTURE MODEL FOR UNSUPERVISED ANOMALY DETECTION (Zong et al., ICLR 2018)\n",
    "\n",
    "https://www.kaggle.com/code/shelars1985/anomaly-detection-using-gaussian-distribution/notebook\n",
    "\n",
    "https://github.com/tsmatz/gmm/blob/master/01-gmm-em-algorithm.ipynb\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
